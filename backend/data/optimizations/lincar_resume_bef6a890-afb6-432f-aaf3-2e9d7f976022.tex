\documentclass[letterpaper,11pt]{article}
\usepackage{fontawesome}
\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}
\usepackage{adjustbox}
\usepackage{ragged2e}
\usepackage{changepage}

\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

\addtolength{\oddsidemargin}{-0.5in}
\addtolength{\evensidemargin}{-0.5in}
\addtolength{\textwidth}{1in}
\addtolength{\topmargin}{-0.5in}
\addtolength{\textheight}{1.0in}

\urlstyle{same}

\setlength{\parindent}{0pt}
\setlength{\parskip}{1pt}
\setlength{\tabcolsep}{0in}

\titleformat{\section}{
\vspace{-4pt}\scshape\raggedright\large
}{}{0em}{}[\color{black}\titlerule \vspace{-4pt}]

\pdfgentounicode=1

%-------------------------
% Custom Commands
%-------------------------
\newcommand{\resumeItem}[1]{
\begin{tabularx}{\linewidth}{@{}lX@{}}
\raisebox{0.25ex}{\tiny\textbullet} & \small #1 \\
\end{tabularx}
}
\newcommand{\resumeSubheading}[4]{\vspace{-2pt}\item
\begin{tabularx}{\linewidth}{@{}X@{\hfill}r@{}}
\textbf{#1} & #2 \\
{\small #3} & {\small #4} \\
\end{tabularx}
\vspace{-6pt}
}
\newcommand{\resumeProjectHeading}[2]{\item
\begin{tabularx}{\linewidth}{@{}X@{\hfill}r@{}}
\textbf{#1} & #2 \\
\end{tabularx}
\vspace{-6pt}
}
\newcommand{\resumeSubItem}[1]{\resumeItem{#1}\vspace{-4pt}}
\renewcommand\labelitemii{$\vcenter{\hbox{\tiny$\bullet$}}$}
\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=0in, label={}]} 
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}[leftmargin=*, itemsep=2pt, topsep=2pt, parsep=0pt]}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-5pt}}

%-------------------------
% Document
%-------------------------
\begin{document}

%-----------Header-----------
\begin{center}
{\Huge \scshape Dharama Teja Samudrala} \\ \vspace{2pt} 
New York, NY 14221 \\ \vspace{2pt}
\small
+18573983456 $|$ \href{mailto:dharmatejas102@gmail.com}{dharmatejas102@gmail.com} $|$ 
\href{https://www.linkedin.com/in/dharmatejasamudrala/}{linkedin} $|$ 
\href{https://github.com/dharmateja03}{github}
\end{center}

%-----------Summary-----------
\section{Summary}
\textbf{Data Scientist} with 3+ years of experience developing end-to-end \textbf{AI/ML solutions} for \textbf{healthcare} and financial services. Skilled in \textbf{machine learning, NLP, deep learning} and leveraging \textbf{large language models (LLMs)} to drive revenue growth and operational efficiency. Proficient in \textbf{Python, SQL, R,} and \textbf{data engineering} best practices. Proven ability to lead impactful projects from ideation to production deployment.

%-----------Experience-----------
\section{Experience}
\resumeSubHeadingListStart
\resumeSubheading{Citi}{NewYork,USA}
{Data Scientist - AI/ML Solutions}{March 2025 -- Present}
\resumeItemListStart
\resumeItem{Developed a \textbf{natural language processing (NLP)} model using \textbf{PyTorch} and fine-tuned \textbf{BERT} to classify customer service inquiries, reducing manual triage time by 30\% for a team of 12 analysts.}
\resumeItem{Built an \textbf{AI-powered chatbot} leveraging \textbf{GPT-3} and a knowledge base of 25K+ articles, handling 40\% of tier-1 support requests and improving customer satisfaction by 18\%.}
\resumeItem{Engineered data pipelines using \textbf{PySpark} and \textbf{AWS Glue} to process 10 TB of unstructured data, enabling real-time insights and reducing ETL runtime by 45\%.}
\resumeItem{Conducted \textbf{predictive analytics} using \textbf{XGBoost} and customer data to forecast churn risk, resulting in proactive retention strategies that reduced attrition by 12\% and increased CLV by \$1.5M.}
\resumeItemListEnd

\resumeSubheading{Fidelity Investments}{Raleigh, NC, USA}
{Data engineer}{Jun 2024 -- Aug 2024}
\resumeItemListStart
\resumeItem{Optimized existing \textbf{PySpark} financial processing workflows on \textbf{AWS EMR} by refactoring data structures and implementing DataFrame optimizations, reducing execution time by 60\% while maintaining data integrity.}
\resumeItem{Evaluated \textbf{AWS Neptune Graph Database} feasibility against existing relational implementations, analyzing performance for team workflow data models.}
\resumeItem{Implemented \textbf{serverless APIs} using \textbf{AWS API Gateway} and \textbf{Lambda} functions, while conducting comprehensive load testing for 25+ internal APIs using performance testing tools to validate scalability.}
\resumeItem{Developed and maintained data pipelines using \textbf{Apache Airflow}, creating DAGs with proper task dependencies.}
\resumeItemListEnd

\resumeSubheading{MetLife}{India}
{AWS Data Engineer}{Dec 2021 -- Jul 2023}
\resumeItemListStart
\resumeItem{Configured and maintained \textbf{Amazon S3} buckets storing 2.5 TB of structured and semi-structured data; implemented partitioning by date and region, improving query time by 25\% in \textbf{Athena}.}
\resumeItem{Built and maintained \textbf{MySQL, PostgreSQL, and MongoDB} databases supporting daily analytics for 120K customer and policy records.}
\resumeItem{Wrote and optimized \textbf{SQL queries} for extraction, aggregation, and reporting, cutting manual reporting time by 40\%.}
\resumeItem{Developed \textbf{PySpark ETL pipelines} to transform and enrich 3 GB of transactional and log data daily from multiple AWS sources.}
\resumeItemListEnd
\vspace{-2mm}

\resumeSubheading{Catalog}{India}
{Machine Learning Intern}{Jan 2021 -- Jun 2021}
\resumeItemListStart
\resumeItem{Conducted distributed data analysis using \textbf{PySpark} to experiment with model scalability and performance on 15 GB of blockchain data.}
\resumeItem{Developed supporting \textbf{Python + SQL ETL pipelines} to preprocess raw data for ML workflows and effective model training.}
\resumeItem{Automated end-to-end training and evaluation pipelines with 8 \textbf{Airflow DAGs} and deployed scalable \textbf{FastAPI microservices} to serve ML models.}
\resumeItemListEnd

\resumeSubHeadingListEnd

%-----------Technical Skills-----------
\section{Technical Skills}
\begin{tabularx}{\textwidth}{@{}lX@{}}
\textbf{Languages \& Libraries:} & Python, SQL, R, PySpark, Pandas, NumPy, scikit-learn, PyTorch \\
\textbf{AI/ML:} & Supervised/Unsupervised Learning, NLP, LLMs (GPT, BERT), Generative AI, MLOps \\
\textbf{Data Engineering:} & AWS (S3, EMR, Glue, Lambda), Apache Airflow, Snowflake, Docker \\
\textbf{Databases:} & MySQL, PostgreSQL, MongoDB, Cassandra, AWS Neptune Graph Database \\
\textbf{Tools \& Methods:} & Git, CI/CD, API Development, Load Testing, Agile/Scrum
\end{tabularx}

%-----------Projects-----------
\section{Projects}
\resumeSubHeadingListStart
\resumeProjectHeading{\textbf{Medical Named Entity Recognition (NER) with BiLSTM-CRF | PyTorch, spaCy, AWS}}{}
\resumeItemListStart
\resumeItem{Developed a \textbf{deep learning model} using \textbf{PyTorch} and a \textbf{BiLSTM-CRF} architecture to extract medical entities (drugs, diseases, symptoms) from 500K unstructured clinical notes.}
\resumeItem{Preprocessed and annotated data using \textbf{spaCy}, handled class imbalance with stratified sampling, and trained model on \textbf{AWS SageMaker}, achieving 91\% F1 score.}
\resumeItem{Deployed model as a \textbf{serverless API} using \textbf{AWS Lambda} and \textbf{API Gateway}, enabling real-time NER for downstream applications, handling 100 requests per second.}
\resumeItemListEnd

\resumeProjectHeading{\textbf{Customer Churn Prediction with Ensemble Learning | Python, XGBoost, Docker}}{}
\resumeItemListStart
\resumeItem{Built an \textbf{ensemble model} combining \textbf{XGBoost}, \textbf{Random Forest}, and \textbf{Logistic Regression} to predict customer churn risk for a telecom client with 250K subscribers.}
\resumeItem{Engineered features from transaction, usage, and customer data using \textbf{Pandas}, handled missing values and outliers, and tuned hyperparameters with \textbf{Bayesian Optimization}.}
\resumeItem{Containerized model training pipeline using \textbf{Docker} and deployed model in production on \textbf{AWS ECS}, enabling automated retraining and inference, reducing churn by 18\%.}
\resumeItemListEnd

\resumeProjectHeading{\textbf{Fraud Detection with Graph Neural Networks | Python, DGL, Neo4j}}{}
\resumeItemListStart
\resumeItem{Developed a \textbf{Graph Neural Network (GNN)} model using \textbf{Deep Graph Library (DGL)} to detect fraudulent transactions in a graph of 10M nodes and 50M edges.}
\resumeItem{Constructed transaction graph from \textbf{Neo4j} database, engineered node and edge features, and trained GNN model on \textbf{AWS EC2} instances with \textbf{GPU} acceleration.}
\resumeItem{Evaluated model on holdout test set, achieving 95\% \textbf{AUROC}, and integrated model into real-time fraud detection pipeline, saving \$500K in potential losses per month.}
\resumeItemListEnd

\resumeSubHeadingListEnd

%-----------Education-----------
\section{Education}
\resumeSubHeadingListStart
\resumeSubheading{Rochester Institute Of Technology}{Rochester, NY, USA}
{Master of Science in Computer Science}{Aug 2023 -- Aug 2025}

\resumeSubHeadingListEnd

%-------------------------------------------
\end{document}