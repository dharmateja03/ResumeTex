\documentclass[letterpaper,11pt]{article}
\usepackage{fontawesome}
\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}
\usepackage{adjustbox}
\usepackage{ragged2e}
\usepackage{changepage}

\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

\addtolength{\oddsidemargin}{-0.5in}
\addtolength{\evensidemargin}{-0.5in}
\addtolength{\textwidth}{1in}
\addtolength{\topmargin}{-0.5in}
\addtolength{\textheight}{1.0in}

\urlstyle{same}

\setlength{\parindent}{0pt}
\setlength{\parskip}{1pt}
\setlength{\tabcolsep}{0in}

\titleformat{\section}{
\vspace{-4pt}\scshape\raggedright\large
}{}{0em}{}[\color{black}\titlerule \vspace{-4pt}]

\pdfgentounicode=1

%-------------------------
% Custom Commands
%-------------------------
\newcommand{\resumeItem}[1]{
\begin{tabularx}{\linewidth}{@{}lX@{}}
\raisebox{0.25ex}{\tiny\textbullet} & \small #1 \\
\end{tabularx}
}
\newcommand{\resumeSubheading}[4]{\vspace{-2pt}\item
\begin{tabularx}{\linewidth}{@{}X@{\hfill}r@{}}
\textbf{#1} & #2 \\
{\small #3} & {\small #4} \\
\end{tabularx}
\vspace{-6pt}
}
\newcommand{\resumeProjectHeading}[2]{\item
\begin{tabularx}{\linewidth}{@{}X@{\hfill}r@{}}
\textbf{#1} & #2 \\
\end{tabularx}
\vspace{-6pt}
}
\newcommand{\resumeSubItem}[1]{\resumeItem{#1}\vspace{-4pt}}
\renewcommand\labelitemii{$\vcenter{\hbox{\tiny$\bullet$}}$}
\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=0in, label={}]} 
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}[leftmargin=*, itemsep=2pt, topsep=2pt, parsep=0pt]}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-5pt}}

%-------------------------
% Document
%-------------------------
\begin{document}

%-----------Header-----------
\begin{center}
{\Huge \scshape Dharama Teja Samudrala} \\ \vspace{2pt} 
New York, NY 14221 \\ \vspace{2pt}
\small
+18573983456 $|$ \href{mailto:dharmatejas102@gmail.com}{dharmatejas102@gmail.com} $|$ 
\href{https://www.linkedin.com/in/dharmatejasamudrala/}{linkedin} $|$ 
\href{https://github.com/dharmateja03}{github}
\end{center}

%-----------Summary-----------
\section{Summary}
\textbf{Data Engineer / Software Engineer} with 3+ years of experience building scalable data pipelines and infrastructure in \textbf{AWS, Snowflake, and Python} for \textbf{healthcare, retail, and finance}. Proven track record designing \textbf{ETL/ELT workflows}, optimizing \textbf{SQL/NoSQL databases}, and deploying production pipelines for \textbf{TB-scale datasets}. Skilled in \textbf{object-oriented programming}, \textbf{containerization}, and \textbf{CI/CD}. Passionate about solving complex data challenges.

%-----------Experience-----------
\section{Experience}
\resumeSubHeadingListStart
\resumeSubheading{Citi}{NewYork,USA}
{Data Engineer}{March 2025 -- Present}
\resumeItemListStart
\resumeItem{Designed and deployed 25+ scalable ETL/ELT pipelines using \textbf{Airflow, PySpark, AWS Glue}, automating ingestion from 10+ sources and reducing manual processing by 45\%.}
\resumeItem{Built real-time streaming infrastructure with \textbf{Kafka, Flume, Zookeeper} to process over 600K events/day with sub-second latency, improving data freshness by 80\%.}
\resumeItem{Optimized data storage and querying across \textbf{Amazon S3, Redshift, Snowflake, BigQuery} using partitioning and compression, reducing query latency by 38\% and costs by 27\%.}
\resumeItem{Integrated and maintained 8+ data sources (\textbf{MySQL, PostgreSQL, MongoDB, Cassandra, HBase}) into unified warehouses on AWS S3 and Snowflake, achieving 99.9\% uptime.}
\resumeItem{Implemented \textbf{CI/CD and monitoring} with Jenkins, AWS CodePipeline, and Airflow, adding automated data quality checks that caught 95\% of anomalies pre-deployment.}
\resumeItemListEnd

\resumeSubheading{Fidelity Investments}{Raleigh, NC, USA}
{Data engineer}{Jun 2024 -- Aug 2024}
\resumeItemListStart
\resumeItem{Optimized PySpark financial processing workflows on \textbf{AWS EMR} by refactoring data structures and DataFrame optimizations, reducing execution time by 60\%.}
\resumeItem{Evaluated \textbf{AWS Neptune Graph Database} feasibility for team workflow data models.}
\resumeItem{Implemented serverless APIs using \textbf{AWS API Gateway and Lambda}, conducting load testing for 25+ internal APIs to validate scalability.}
\resumeItem{Developed and maintained data pipelines using \textbf{Apache Airflow}, creating DAGs with proper task dependencies.}
\resumeItemListEnd

\resumeSubheading{MetLife}{India}
{AWS Data Engineer}{Dec 2021 -- Jul 2023}
\resumeItemListStart
\resumeItem{Configured and maintained \textbf{Amazon S3} buckets storing 2-3 TB of structured and semi-structured data; implemented partitioning, improving Athena query time by 25\%.}
\resumeItem{Built and maintained \textbf{MySQL, PostgreSQL, and MongoDB} databases supporting analytics for 150K+ customer and policy records.}
\resumeItem{Wrote and optimized \textbf{SQL queries} for extraction, aggregation, and reporting, cutting manual reporting time by 40\%.}
\resumeItem{Developed \textbf{PySpark ETL pipelines} to transform and enrich 1-5 GB of transactional and log data daily from multiple AWS sources.}
\resumeItem{Designed \textbf{Airflow DAGs} for ETL workflows, automating 5-10 recurring jobs with dependencies, retries, and failure alerting.}
\resumeItem{Configured \textbf{AWS Lambda} triggers for event-driven ingestion on S3 uploads and SQS messages, reducing manual pipeline runs by 30\%.}
\resumeItem{Implemented data quality checks and audit logs in pipelines, ensuring 99\%+ consistency between raw and processed data.}
\resumeItem{Deployed ETL scripts through \textbf{CI/CD (Jenkins, GitLab Actions)}, automating packaging and version control to cut deployment effort by 35\%.}
\resumeItem{Managed \textbf{Snowflake and Redshift} warehouses containing 0.5-1 TB of data; optimized query plans and compression to reduce compute costs by 20\%.}
\resumeItemListEnd

\resumeSubheading{Catalog}{India}
{Machine Learning Intern}{Jan 2021 -- Jun 2021}
\resumeItemListStart
\resumeItem{Conducted large-scale distributed data analysis using \textbf{PySpark} to experiment with model scalability and performance on high-volume blockchain data.}
\resumeItem{Developed supporting \textbf{Python + SQL ETL pipelines} to preprocess raw blockchain transaction data for ML workflows and model training.}
\resumeItem{Automated training and evaluation pipelines with 10+ \textbf{Airflow DAGs} and deployed scalable \textbf{FastAPI microservices} to serve ML models.}
\resumeItemListEnd

\resumeSubHeadingListEnd

%-----------Technical Skills-----------
\section{Technical Skills}
\begin{tabularx}{\textwidth}{@{}lX@{}}
\textbf{Languages \& Frameworks:} & Python, Java, SQL, PySpark, Pandas, NumPy \\ 
\textbf{Data Engineering \& Cloud:} & AWS (S3, Glue, EMR, Lambda, API Gateway), Snowflake, Airflow, Docker, Kubernetes, CI/CD \\
\textbf{Databases:} & MySQL, PostgreSQL, MongoDB, Cassandra, HBase, AWS Redshift, Google BigQuery \\
\textbf{Tools \& Platforms:} & Git, Jira, Agile, Linux, Jupyter, PyCharm, IntelliJ
\end{tabularx}

%-----------Projects-----------
\section{Projects}
\textbf{Microservices Communication Framework | Go, gRPC,Docker, Kubernetes} 
\resumeItemListStart
\resumeItem{Architected 3 \textbf{gRPC microservices} (User, Order, Payment) with Envoy sidecar proxies; implemented mTLS, circuit breakers, and retry policies for resilient inter-service communication.}
\resumeItem{Built observability pipeline using \textbf{Prometheus, Grafana, and Jaeger}; automated deployment with \textbf{Docker Compose and Helm charts}; benchmarked latency across 100K+ requests.}
\resumeItem{Reduced P99 latency by 24\% via load balancing; canary routing cut deployment risk by 40\%; quantified service mesh overhead at 8\% for informed adoption decisions.}
\resumeItemListEnd

%-----------Education-----------
\section{Education}
\resumeSubHeadingListStart
\resumeSubheading{Rochester Institute Of Technology}{Rochester, NY, USA}
{Master of Science in Computer Science}{Aug 2023 -- Aug 2025}
\resumeSubHeadingListEnd

\end{document}